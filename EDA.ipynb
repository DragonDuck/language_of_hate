{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language of Reddit\n",
    "This project looks at commonly used words in specific subreddits. Frequencies are compared to a baseline that is derived from the top $20$ popular subreddits. The most popular subreddits are assumed to be the most neutral in terms of their language and consequently they'll attract a broad audience rather than a subculture.\n",
    "\n",
    "Also note that I will only extract top-level comments, so no replies. This has three reasons:\n",
    "1. Subreddits often enforce stricter rules for the top-level comments. This means that top-level and lower-level comments will have inherently different language. For example, top-level comments in AskReddit threads will be stories or answers to the question being asked whereas replies to the top-level comments will be reactions.\n",
    "2. The number of replies a comment get depends a great deal on how early it is made. Additionally, replies in conversations will tend to repeat language. Consequently, including replies to top-level comments would introduce a temporal bias towards early comments.\n",
    "3. Reddit is huge and scraping ALL comments to a thread would take impossibly long and cause an unethical strain on the Reddit servers. As diversity in language is more important than sampling depth, I want to focus on capturing a few comments in many threads rather than many comments in a few threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data with the API and storing it in a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import sqlite3\n",
    "import _auth\n",
    "reddit = _auth.get_api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"reddit_comments.sqlite3\")\n",
    "cur = con.cursor()\n",
    "cur.execute(\"DROP TABLE IF EXISTS comments;\")\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS comments (\n",
    "    subreddit TEXT,\n",
    "    thread_url TEXT, \n",
    "    thread_title TEXT, \n",
    "    thread_id TEXT, \n",
    "    comment_id TEXT PRIMARY KEY,\n",
    "    comment_body TEXT);\"\"\")\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_subreddit(subreddit, db=\"reddit_comments.sqlite3\", threads=50, ignore_existing=False):\n",
    "    \"\"\"\n",
    "    Looks at the top threads of all time in a given subreddit, mines the top comments, \n",
    "    and adds them to a database. This function doesn't do anything if the subreddit already\n",
    "    exists in the database unless explicitly told to add entries. In this case, it does not\n",
    "    delete any entries and only adds new comments the database doesn't know yet.\n",
    "    \"\"\"\n",
    "    \n",
    "    con = sqlite3.connect(db)\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    if subreddit.url in [ii[0] for ii in cur.execute(\n",
    "        \"select distinct subreddit from comments\").fetchall()] and not ignore_existing:\n",
    "        con.close()\n",
    "        return None\n",
    "    \n",
    "    for thread in subreddit.top(limit=50):\n",
    "        for comment in thread.comments:\n",
    "            try:\n",
    "                sql = \"INSERT OR IGNORE INTO comments \\\n",
    "                    (subreddit, thread_url, thread_title, \\\n",
    "                    thread_id, comment_id, comment_body) \\\n",
    "                    VALUES (?, ?, ?, ?, ?, ?);\"\n",
    "                values = (\n",
    "                    subreddit.url, thread.url, thread.title, \n",
    "                    thread.name, comment.name, comment.body)\n",
    "                cur.execute(sql, values)\n",
    "                con.commit()\n",
    "            except  AttributeError:\n",
    "                    pass\n",
    "    \n",
    "    con.close()\n",
    "    return None\n",
    "\n",
    "def get_comments_from_subreddits(subreddits, db=\"reddit_comments.sqlite3\"):\n",
    "    \"\"\"\n",
    "    Returns all comments belonging to certain subreddits\n",
    "    \"\"\"\n",
    "    \n",
    "    con = sqlite3.connect(db)\n",
    "    cur = con.cursor()\n",
    "    comments = cur.execute(\n",
    "        \"SELECT * from comments where subreddit in ('{}')\".format(\n",
    "            \"','\".join(baseline_subreddits))).fetchall()\n",
    "    con.close()\n",
    "    return comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: popular subreddits\n",
    "The choice lies between \"default\" and \"popular\" subreddits. Because the default subreddits are defined by Reddit administrators, they may include inherent biases and corporate policies. To avoid this, I look at the popular subreddits by user participation.\n",
    "\n",
    "I loop through all of these subreddits and extract top-level comments from the top $50$ threads of all time of each subreddit (resulting in a total of $1\\,000$ threads). Reddit's API limitation means that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_subreddits = []\n",
    "for subreddit in reddit.subreddits.popular(limit=20):\n",
    "    baseline_subreddits.append(subreddit.url)\n",
    "    mine_subreddit(subreddit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = baseline_subreddits\n",
    "comments = [entry[-1] for entry in get_comments_from_subreddits(subreddits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
